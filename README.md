# ğŸ©º Hypertension Risk Predictor

**Live demo:** [https://hypertension-predictor.streamlit.app](https://hypertension-predictor.streamlit.app)

A Streamlit app that predicts a patientâ€™s hypertension risk from simple inputs, highlights the key factors influencing the prediction, and generates **personalized health guidance** using Google **Gemini** (Vertex AI). It also includes **Sign Up / Sign In** and a **Dashboard** for viewing and exporting past predictions and LLM feedback.

---

## âœ¨ Features

* **Prediction UI**
  Collects Age, BMI, Salt Intake, Stress, Sleep, BP history, Medication, Family history, Exercise, and Smoking status â†’ predicts risk.
* **Explainability**
  Shows **global feature importances** (from your model) and a **local snapshot** of top factors for the current case.
* **Personalized Guidance (LLM)**
  Uses Gemini (Vertex AI) to produce clear, non-judgmental, actionable tips tailored to the patientâ€™s inputs and model outcome.
* **Authentication & Dashboard**
  Users can **Sign Up / Sign In**. After sign-in, a **Dashboard** lists past predictions, lets you inspect details, and **export CSV/JSON**.
* **Local logging (SQLite)**
  Stores user, timestamp, patient input, model output, key factors, and LLM guidance.

---

## ğŸ§± Architecture

* **Frontend:** Streamlit (`app.py`)
* **Inference & Preprocessing:** `inference.py`
  Loads `best_rf_model.joblib`, `scaler.joblib`, and `feature_names.joblib`; aligns/encodes inputs exactly like training.
* **LLM Client:** `vertex_config.py` using `google-genai` (Vertex AI)
* **Database:** SQLite via SQLAlchemy (`db.py`)

  * `users` (simple auth)
  * `prediction_logs` (audit trail)
* **Dashboard:** Built into the main app (gated behind auth)
* **Scripts / Tests:**

  * `scripts/verify_artifacts.py` quick artifact sanity check
  * `scripts/export_feature_names.py` generate `feature_names.joblib`
  * `tests/` basic unit tests & CI (GitHub Actions)

---

## ğŸ“ Repository structure

```
.
â”œâ”€â”€ app.py
â”œâ”€â”€ inference.py
â”œâ”€â”€ vertex_config.py
â”œâ”€â”€ db.py
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ best_rf_model.joblib
â”‚   â”œâ”€â”€ scaler.joblib
â”‚   â””â”€â”€ feature_names.joblib
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ verify_artifacts.py
â”‚   â””â”€â”€ export_feature_names.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ conftest.py
â”‚   â””â”€â”€ test_inference.py
â”œâ”€â”€ .streamlit/
â”‚   â”œâ”€â”€ config.toml
â”‚   â””â”€â”€ secrets.toml            # DO NOT COMMIT (ignored)
â”œâ”€â”€ .github/workflows/
â”‚   â”œâ”€â”€ ci.yml
â”‚   â””â”€â”€ codeql.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸš€ Getting started (local)

### 1) Clone & create a virtual environment

```bash
git clone <your-repo-url> hypertension-predictor
cd hypertension-predictor
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install --upgrade pip
pip install -r requirements.txt
```

### 2) Place model artifacts

Put these **three files** in `models/`:

* `best_rf_model.joblib`
* `scaler.joblib`
* `feature_names.joblib`  â† must match the **exact** columns of your training design matrix.

> Donâ€™t have `feature_names.joblib` yet?
>
> * If you have your **final X_train CSV** (already one-hot encoded):
>
>   ```bash
>   python scripts/export_feature_names.py --design-csv path/to/X_train_final.csv
>   ```
> * If you only have a **raw training CSV**:
>
>   ```bash
>   python scripts/export_feature_names.py --raw-csv path/to/train.csv --target-column TARGET_NAME
>   ```

### 3) Configure Vertex AI (Gemini)

**Option A (recommended for local):** point to a real key file

```bash
export GOOGLE_APPLICATION_CREDENTIALS="$HOME/keys/vertex-sa.json"
export PROJECT_ID="your-gcp-project-id"
export LOCATION="us-central1"
```

**Option B (Streamlit secrets):** paste into `.streamlit/secrets.toml` (not committed)

```toml
[gcp]
project_id = "your-gcp-project-id"
location   = "us-central1"
service_account_json = """
{ ...full service account JSON with \\n in the private_key... }
"""
```

> âš ï¸ Ensure the `private_key` in the JSON contains **escaped** newlines (`\\n`) â€” not literal line breaks.

### 4) Initialize DB & run a quick artifact check (optional)

```bash
python scripts/verify_artifacts.py
```

### 5) Run the app

```bash
streamlit run app.py
```

Open the local URL shown, **Sign Up** to create a user, **Sign In**, then try a prediction and visit the **Dashboard** tab.

---

## ğŸ” Authentication notes

* The app includes a minimal user system in `db.py` using **bcrypt**.
* First-time: click **Sign Up** in the app to create an account.
* Data is stored in `app.db` (SQLite) by default. Set `DB_URL` to use Postgres if desired, e.g.:

  ```
  export DB_URL="postgresql+psycopg2://user:password@host:5432/dbname"
  ```

---

## â˜ï¸ Deploying to Streamlit Community Cloud

1. **Push** your repo to GitHub (make sure `.streamlit/secrets.toml`, any `*.json` keys, `app.db`, and `models/*.joblib` are **ignored**).
2. On Streamlit Cloud, **Create app** from your repo.
3. In **App â†’ Settings â†’ Secrets**, paste:

   ```toml
   [gcp]
   project_id = "your-gcp-project-id"
   location   = "us-central1"
   service_account_json = """
   { ...full service account JSON with \\n in the private_key... }
   """
   ```
4. (Optional) Upload your model artifacts somewhere accessible (you can commit **non-sensitive** artifacts if licensing allows; otherwise host them privately and load at startup).
5. Deploy. Sign up a user and test.

---

## ğŸ§ª Tests & CI

* Run tests:

  ```bash
  pytest -q
  ```
* CI: GitHub Actions (`.github/workflows/ci.yml`) runs lint + tests on pushes/PRs.
* Security scanning: CodeQL workflow (`codeql.yml`) runs weekly.

---

## ğŸ”§ Configuration

* **LLM model & settings:** fixed in `app.py`

  ```python
  LLM_MODEL_NAME = "gemini-2.5-pro"
  LLM_TEMPERATURE = 0.3
  LLM_TOP_P = 0.95
  LLM_MAX_TOKENS = 2048
  ```
* **Theme & server:** `.streamlit/config.toml`
  (Keep `enableXsrfProtection = true`; remove `enableCORS=false` to avoid warnings.)
* **DB URL:** `DB_URL` env var (defaults to `sqlite:///app.db`).

---

## ğŸ§° Troubleshooting

* **â€œLLM feedback unavailable: â€¦ not a valid json file â€¦ Invalid control character â€¦â€**
  Your service account JSON in secrets has raw newlines. Use `\\n` escapes or set `GOOGLE_APPLICATION_CREDENTIALS` to point to the key file.

* **Partial/short LLM output**
  We stitch all text parts and increased `max_output_tokens` to 2048. If you still see truncation, raise it further.

* **â€œfeature_names mismatch / wrong column countâ€**
  `feature_names.joblib` **must** match the exact post-dummies order used in training. Re-export with `scripts/export_feature_names.py`.

* **macOS LibreSSL warning**
  Harmless for local dev. Consider using Python 3.10+ to link against a newer OpenSSL.

* **Nothing appears on Dashboard**
  Make a prediction first; only successful runs are logged. Also ensure youâ€™re **signed in** (Dashboard is gated).

* **GitHub rejects push for secrets**
  Rotate/revoke the leaked key in GCP, purge history with `git filter-repo`, and force-push. Donâ€™t commit `.streamlit/secrets.toml`.

---

## ğŸ“„ Data & Privacy

* This tool is for **educational purposes** and does **not** replace professional medical advice.
* Avoid storing personally identifiable information (PII) in free-text fields.
* LLM calls send the minimal necessary context to Vertex AI.

---

## ğŸ“¦ Requirements (key packages)

See `requirements.txt`, including:

* `streamlit`
* `pandas`
* `scikit-learn` (for scaler compatibility if needed)
* `joblib`
* `sqlalchemy`
* `bcrypt`
* `google-genai` (Vertex AI client)

---

## ğŸ“ License

Add your preferred license (MIT/Apache-2.0/etc.) to a `LICENSE` file.

---

## ğŸ™Œ Acknowledgements

* Streamlit for the rapid UI
* Google Vertex AI Gemini for LLM guidance
* scikit-learn for classical ML utilities
* Boniface Emmanuel, My Research Assistant

